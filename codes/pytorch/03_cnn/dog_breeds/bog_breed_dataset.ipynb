{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import glob\n",
    "import numpy as np \n",
    "\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def test_network(net, trainloader):\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "    dataiter = iter(trainloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    # Create Variables for the inputs and targets\n",
    "    inputs = Variable(images)\n",
    "    targets = Variable(images)\n",
    "\n",
    "    # Clear the gradients from all Variables\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass, then backward pass, then update weights\n",
    "    output = net.forward(inputs)\n",
    "    loss = criterion(output, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def imshow(image, ax=None, title=None, normalize=True):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    image = image.numpy().transpose((1, 2, 0))\n",
    "\n",
    "    if normalize:\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        image = std * image + mean\n",
    "        image = np.clip(image, 0, 1)\n",
    "\n",
    "    ax.imshow(image)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.tick_params(axis='both', length=0)\n",
    "    ax.set_xticklabels('')\n",
    "    ax.set_yticklabels('')\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_PATH = \"Images\"\n",
    "if os.path.exists(TARGET_PATH):\n",
    "    shutil.rmtree(TARGET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"images.tar\"\n",
    "tar = tarfile.open(fname, \"r:tar\")\n",
    "tar.extractall()\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir(TARGET_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir_name in os.listdir(TARGET_PATH):\n",
    "    breed_name = dir_name.split(\"-\")[-1].lower()\n",
    "    source_dir = os.path.join(TARGET_PATH, dir_name)\n",
    "    target_dir = os.path.join(TARGET_PATH, breed_name)\n",
    "    shutil.move(source_dir, target_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for filepath in glob.iglob(f'{TARGET_PATH}/**/*.jpg', recursive=True):\n",
    "    breed_name = filepath.split(\"/\")[1]\n",
    "    dataset.append([filepath, breed_name])\n",
    "dataset = np.array(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_image, test_image, train_target, test_target = train_test_split(dataset[:,0], dataset[:,1], stratify=dataset[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.Series(train_target).value_counts() / len(train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(test_target).value_counts() / len(test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"dataset\"\n",
    "shutil.rmtree(DATA_PATH)\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    os.mkdir(DATA_PATH)\n",
    "    os.makedirs(os.path.join(DATA_PATH, \"train\"))\n",
    "    os.makedirs(os.path.join(DATA_PATH, \"test\"))\n",
    "    \n",
    "    for breed_name in set(test_target):\n",
    "        os.makedirs(os.path.join(DATA_PATH, \"train\", breed_name))\n",
    "        os.makedirs(os.path.join(DATA_PATH, \"test\", breed_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "for filepath, taregt_dir in zip(train_image.tolist(), train_target.tolist()):        \n",
    "    filename = filepath.split(\"/\")[-1]\n",
    "    source_path = filepath\n",
    "    target_dir = os.path.join(DATA_PATH, \"train\", taregt_dir, filename)\n",
    "    shutil.copy(source_path, target_dir) \n",
    "    \n",
    "for filepath, taregt_dir in zip(test_image.tolist(), test_target.tolist()):        \n",
    "    filename = filepath.split(\"/\")[-1]\n",
    "    source_path = filepath\n",
    "    target_dir = os.path.join(DATA_PATH, \"test\", taregt_dir, filename)\n",
    "    shutil.copy(source_path, target_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    " \n",
    "im = Image.open(target_dir)\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "def process(filename: str=None) -> None:\n",
    "    \"\"\"\n",
    "    View multiple images stored in files, stacking vertically\n",
    "\n",
    "    Arguments:\n",
    "        filename: str - path to filename containing image\n",
    "    \"\"\"\n",
    "    image = mpimg.imread(filename)\n",
    "    # <something gets done here>\n",
    "    plt.figure()\n",
    "    plt.imshow(image)\n",
    "\n",
    "    \n",
    "idx = np.random.choice(len(dataset), 10)\n",
    "\n",
    "images = dataset[:, 0][idx]\n",
    "\n",
    "for file in images:\n",
    "    process(file)\n",
    "    \n",
    "print(dataset[:, 1][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "# TODO: Define transforms for the training data and testing data\n",
    "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                            [0.229, 0.224, 0.225])])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "\n",
    "DATASET_PATH = \"dataset\"\n",
    "# Pass transforms in here, then run the next cell to see how the transforms look\n",
    "train_data = datasets.ImageFolder(DATASET_PATH + '/train', transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(DATASET_PATH + '/test', transform=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(test_loader)\n",
    "\n",
    "images, labels = next(data_iter)\n",
    "fig, axes = plt.subplots(figsize=(10,4), ncols=4)\n",
    "for ii in range(4):\n",
    "    ax = axes[ii]\n",
    "    imshow(images[ii], ax=ax, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lablup FF 20.07 on Python 3.6 (CUDA 10.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
